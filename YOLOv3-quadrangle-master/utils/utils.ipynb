{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import random\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from shapely.geometry import Polygon\n",
        "import shapely\n",
        "\n",
        "def load_classes(path):\n",
        "\t\"\"\"\n",
        "\tLoads class labels at 'path'\n",
        "\t\"\"\"\n",
        "\tfp = open(path, \"r\")\n",
        "\tnames = fp.read().split(\"\\n\")[:-1]\n",
        "\treturn names\n",
        "\n",
        "def model_info(model):  # Plots a line-by-line description of a PyTorch model\n",
        "\tnP = sum(x.numel() for x in model.parameters())  # number parameters\n",
        "\tnG = sum(x.numel() for x in model.parameters() if x.requires_grad)  # number gradients\n",
        "\tprint('\\n%4s %70s %9s %12s %20s %12s %12s' % ('', 'name', 'gradient', 'parameters', 'shape', 'mu', 'sigma'))\n",
        "\tfor i, (name, p) in enumerate(model.named_parameters()):\n",
        "\t\tname = name.replace('module_list.', '')\n",
        "\t\tprint('%4g %70s %9s %12g %20s %12g %12g' % (\n",
        "\t\t\ti, name, p.requires_grad, p.numel(), list(p.shape), p.mean(), p.std()))\n",
        "\tprint('\\n%g layers, %g parameters, %g gradients' % (i + 1, nP, nG))\n",
        "\n",
        "def plot_one_box(x, img, color=None, label=None, line_thickness=None):  # Plots one bounding box on image img\n",
        "\ttl = line_thickness or round(0.001 * max(img.shape[0:2])) + 1  # line thickness\n",
        "\tcolor = color or [random.randint(0, 255) for _ in range(3)]\n",
        "\n",
        "\t#c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
        "\t#cv2.rectangle(img, c1, c2, color, thickness=tl)\n",
        "\n",
        "\tcv2.line(img, (int(x[0]), int(x[1])), (int(x[2]), int(x[3])), color, tl)\n",
        "\tcv2.line(img, (int(x[2]), int(x[3])), (int(x[4]), int(x[5])), color, tl)\n",
        "\tcv2.line(img, (int(x[4]), int(x[5])), (int(x[6]), int(x[7])), color, tl)\n",
        "\tcv2.line(img, (int(x[6]), int(x[7])), (int(x[0]), int(x[1])), color, tl)\n",
        "\n",
        "\n",
        "\tif label:\n",
        "\t\ttf = max(tl - 1, 1)  # font thickness\n",
        "\t\tt_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
        "\t\tc2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
        "\t\tcv2.rectangle(img, c1, c2, color, -1)  # filled\n",
        "\t\tcv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
        "\n",
        "def bbox_iou(box1, box2):\n",
        "\t\"\"\"\n",
        "\tReturns the IoU of two bounding boxes\n",
        "\t\"\"\"\n",
        "\tcuda = torch.cuda.is_available()\n",
        "\tdevice = torch.device('cuda:0' if cuda else 'cpu')\n",
        "\n",
        "\tnBox = box1.size()[0]\n",
        "\n",
        "\tiou = torch.zeros(nBox)\n",
        "\tfor i in range(0, nBox):\n",
        "\t\tpolygon1 = Polygon(box1[i,:].view(4,2)).convex_hull\n",
        "\t\tpolygon2 = Polygon(box2[i,:].view(4,2)).convex_hull\n",
        "\t\tif polygon1.intersects(polygon2):\n",
        "\t\t\ttry:\n",
        "\t\t\t\tinter_area = polygon1.intersection(polygon2).area\n",
        "\t\t\t\tunion_area = polygon1.union(polygon2).area\n",
        "\t\t\t\tiou[i] =  inter_area / union_area\n",
        "\t\t\texcept shapely.geos.TopologicalError:\n",
        "\t\t\t\tprint('shapely.geos.TopologicalError occured, iou set to 0')\n",
        "\t\t\t\tiou[i] = 0\n",
        "\n",
        "\treturn iou.to(device)\n",
        "\n",
        "def reorganize_targets(t, nTb):\n",
        "\ttc = t[:, 0]\n",
        "\tt = t[:, 1:9].view(nTb, 4, 2)\n",
        "\n",
        "\tx = t[..., 0]\n",
        "\ty = t[..., 1]\n",
        "\ty_sorted, y_indices = torch.sort(y)\n",
        "\t\n",
        "\tx_sorted = torch.zeros(nTb, 4)\n",
        "\tfor i in range(0, nTb):\n",
        "\t\tx_sorted[i] = x[i, y_indices[i]]\n",
        "\n",
        "\n",
        "\tx_sorted[:, :2], x_top_indices = torch.sort(x_sorted[:, :2])\n",
        "\tx_sorted[:, 2:4], x_bottom_indices = torch.sort(x_sorted[:, 2:4], descending=True)\n",
        "\tfor i in range(0, nTb):\n",
        "\t\ty_sorted[i, :2] = y_sorted[i, :2][x_top_indices[i]]\n",
        "\t\ty_sorted[i, 2:4] = y_sorted[i, 2:4][x_bottom_indices[i]]\n",
        "\n",
        "\tt = torch.cat((x_sorted[:,0].unsqueeze(1), y_sorted[:,0].unsqueeze(1), x_sorted[:,1].unsqueeze(1), y_sorted[:,1].unsqueeze(1), \n",
        "\t\t\t\t\t x_sorted[:,2].unsqueeze(1), y_sorted[:,2].unsqueeze(1), x_sorted[:,3].unsqueeze(1), y_sorted[:,3].unsqueeze(1)), 1)\n",
        "\n",
        "\treturn torch.cat((tc.unsqueeze(1), t), 1)\n",
        "\n",
        "\n",
        "def build_targets(pred_boxes, pred_conf, pred_cls, target, anchor_wh, nA, nC, nG, requestPrecision):\n",
        "\t\"\"\"\n",
        "\treturns nT, nCorrect, tx, ty, tw, th, tconf, tcls\n",
        "\t\"\"\"\n",
        "\tnB = len(target)  # number of images in batch\n",
        "\tnT = [len(x) for x in target]  # torch.argmin(target[:, :, 4], 1)  # targets per batch\n",
        "\tt1_x = torch.zeros(nB, nA, nG, nG)  # batch size (4), number of anchors (3), number of grid points (13)\n",
        "\tt1_y = torch.zeros(nB, nA, nG, nG)\n",
        "\tt2_x = torch.zeros(nB, nA, nG, nG)\n",
        "\tt2_y = torch.zeros(nB, nA, nG, nG)\n",
        "\tt3_x = torch.zeros(nB, nA, nG, nG)\n",
        "\tt3_y = torch.zeros(nB, nA, nG, nG)\n",
        "\tt4_x = torch.zeros(nB, nA, nG, nG)\n",
        "\tt4_y = torch.zeros(nB, nA, nG, nG)\n",
        "\ttconf = torch.ByteTensor(nB, nA, nG, nG).fill_(0)\n",
        "\ttcls = torch.ByteTensor(nB, nA, nG, nG, nC).fill_(0)  # nC = number of classes\n",
        "\tTP = torch.ByteTensor(nB, max(nT)).fill_(0)\n",
        "\tFP = torch.ByteTensor(nB, max(nT)).fill_(0)\n",
        "\tFN = torch.ByteTensor(nB, max(nT)).fill_(0)\n",
        "\tTC = torch.ShortTensor(nB, max(nT)).fill_(-1)  # target category\n",
        "\n",
        "\tcuda = torch.cuda.is_available()\n",
        "\tdevice = torch.device('cuda:0' if cuda else 'cpu')\n",
        "\n",
        "\tfor b in range(nB):\n",
        "\t\tnTb = nT[b]  # number of targets per image\n",
        "\t\tif nTb == 0:\n",
        "\t\t\tcontinue\n",
        "\t\tt = target[b]\n",
        "\t\tFN[b, :nTb] = 1\n",
        "\n",
        "\t\tt = reorganize_targets(t, nTb)\n",
        "\n",
        "\t\t# Convert to position relative to box\n",
        "\t\tTC[b, :nTb] = t[:, 0].long()\n",
        "\t\tgp1_x, gp1_y = t[:, 1] * nG, t[:, 2] * nG\n",
        "\t\tgp2_x, gp2_y = t[:, 3] * nG, t[:, 4] * nG\n",
        "\t\tgp3_x, gp3_y = t[:, 5] * nG, t[:, 6] * nG\n",
        "\t\tgp4_x, gp4_y = t[:, 7] * nG, t[:, 8] * nG\n",
        "\t\t# Get grid box indices and prevent overflows (i.e. 13.01 on 13 anchors)\n",
        "\t\tgp1_i, gp1_j = torch.clamp(torch.round(gp1_x).long(), min=0, max=nG - 1), torch.clamp(torch.round(gp1_y).long(), min=0, max=nG - 1)\n",
        "\t\tgp2_i, gp2_j = torch.clamp(torch.round(gp2_x).long(), min=0, max=nG - 1), torch.clamp(torch.round(gp2_y).long(), min=0, max=nG - 1)\n",
        "\t\tgp3_i, gp3_j = torch.clamp(torch.round(gp3_x).long(), min=0, max=nG - 1), torch.clamp(torch.round(gp3_y).long(), min=0, max=nG - 1)\n",
        "\t\tgp4_i, gp4_j = torch.clamp(torch.round(gp4_x).long(), min=0, max=nG - 1), torch.clamp(torch.round(gp4_y).long(), min=0, max=nG - 1)\n",
        "\n",
        "\t\tbox1 = t[:, 1:9] * nG\n",
        "\n",
        "\t\t# Get each target center\n",
        "\t\tgp_x = torch.cat((gp1_x.unsqueeze(1), gp2_x.unsqueeze(1), gp3_x.unsqueeze(1), gp4_x.unsqueeze(1)), 1).view(-1, 4)\n",
        "\t\tgp_y = torch.cat((gp1_y.unsqueeze(1), gp2_y.unsqueeze(1), gp3_y.unsqueeze(1), gp4_y.unsqueeze(1)), 1).view(-1, 4)\n",
        "\n",
        "\t\tgp_x_min = torch.min(gp_x, 1)[0]\n",
        "\t\tgp_x_max = torch.max(gp_x, 1)[0]\n",
        "\t\tgp_y_min = torch.min(gp_y, 1)[0]\n",
        "\t\tgp_y_max = torch.max(gp_y, 1)[0]\n",
        "\n",
        "\t\tgp_x_center = torch.mean(torch.cat((gp_x_min.unsqueeze(1), gp_x_max.unsqueeze(1)), 1), 1)\n",
        "\t\tgp_y_center = torch.mean(torch.cat((gp_y_min.unsqueeze(1), gp_y_max.unsqueeze(1)), 1), 1)\n",
        "\t\t# Set target center in a certain cell\n",
        "\t\tgp_x_center = torch.round(gp_x_center)\n",
        "\t\tgp_y_center = torch.round(gp_y_center)\n",
        "\n",
        "\t\tx_min = torch.clamp((gp_x_center.unsqueeze(1).repeat(1, nA).view(-1, nA, 1) - anchor_wh[:, 0].view(-1, nA, 1) / 2), min=0, max=nG-1)\n",
        "\t\tx_max = torch.clamp((gp_x_center.unsqueeze(1).repeat(1, nA).view(-1, nA, 1) + anchor_wh[:, 0].view(-1, nA, 1) / 2), min=0, max=nG-1)\n",
        "\t\ty_min = torch.clamp((gp_y_center.unsqueeze(1).repeat(1, nA).view(-1, nA, 1) - anchor_wh[:, 1].view(-1, nA, 1) / 2), min=0, max=nG-1)\n",
        "\t\ty_max = torch.clamp((gp_y_center.unsqueeze(1).repeat(1, nA).view(-1, nA, 1) + anchor_wh[:, 1].view(-1, nA, 1) / 2), min=0, max=nG-1)\n",
        "\n",
        "\t\ttop_left = torch.cat((x_min.view(-1, 1), y_min.view(-1, 1)), 1)\n",
        "\t\ttop_right = torch.cat((x_max.view(-1, 1), y_min.view(-1, 1)), 1)\n",
        "\t\tbottom_right = torch.cat((x_max.view(-1, 1), y_max.view(-1, 1)), 1)\n",
        "\t\tbottom_left = torch.cat((x_min.view(-1, 1), y_max.view(-1, 1)), 1)\n",
        "\t\t# Get bounding boxes\n",
        "\t\tbox2 = torch.cat((top_left, top_right, bottom_right, bottom_left), 1).view(-1, nA, 8)\n",
        "\n",
        "\t\tiou_anch = torch.zeros(nA, nTb, 1)\n",
        "\t\tfor i in range(0, nTb):\n",
        "\t\t\tfor j in range(0, nA):\n",
        "\t\t\t\tpolygon1 = Polygon(box1[i,:].view(4,2)).convex_hull\n",
        "\t\t\t\tpolygon2 = Polygon(box2[i,j,:].view(4,2)).convex_hull\n",
        "\t\t\t\tif polygon1.intersects(polygon2):\n",
        "\t\t\t\t\ttry:\n",
        "\t\t\t\t\t\tinter_area = polygon1.intersection(polygon2).area\n",
        "\t\t\t\t\t\tunion_area = polygon1.union(polygon2).area\n",
        "\t\t\t\t\t\tiou_anch[j, i] =  inter_area / union_area\n",
        "\t\t\t\t\texcept shapely.geos.TopologicalError:\n",
        "\t\t\t\t\t\tprint('shapely.geos.TopologicalError occured, iou set to 0')\n",
        "\n",
        "\t\tiou_anch = iou_anch.squeeze(2)\n",
        "\t\t# Select best iou_pred and anchor\n",
        "\t\tiou_anch_best, a = iou_anch.max(0)  # best anchor [0-2] for each target\n",
        "\t\t\n",
        "\t\t# Select best unique target-anchor combinations\n",
        "\t\tif nTb > 1:\n",
        "\t\t\tiou_order = np.argsort(-iou_anch_best)  # best to worst\n",
        "\n",
        "\t\t\t# Unique anchor selection (slower but retains original order)\n",
        "\t\t\tu = torch.cat((gp1_i, gp1_j, gp2_i, gp2_j, gp3_i, gp3_j, gp4_i, gp4_j, a), 0).view(-1, nTb).cpu().numpy()\n",
        "\t\t\t_, first_unique = np.unique(u[:, iou_order], axis=1, return_index=True)  # first unique indices; each cell response to on target\n",
        "\t\t\ti = iou_order[first_unique]\n",
        "\n",
        "\t\t\t# best anchor must share significant commonality (iou) with target\n",
        "\t\t\ti = i[iou_anch_best[i] > 0.1]\n",
        "\t\t\tif len(i) == 0:\n",
        "\t\t\t\tcontinue\n",
        "\n",
        "\t\t\ta, gp1_i, gp1_j, gp2_i, gp2_j, gp3_i, gp3_j, gp4_i, gp4_j, t = \\\n",
        "\t\t\ta[i], gp1_i[i], gp1_j[i], gp2_i[i], gp2_j[i], gp3_i[i], gp3_j[i], gp4_i[i], gp4_j[i], t[i]\n",
        "\t\t\tif len(t.shape) == 1:\n",
        "\t\t\t\tt = t.view(1, 5)\n",
        "\t\telse:\n",
        "\t\t\tif iou_anch_best < 0.1:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\ti = 0\n",
        "\n",
        "\t\ttc = t[:, 0].long()\n",
        "\t\tgp1_x, gp1_y = t[:, 1] * nG, t[:, 2] * nG\n",
        "\t\tgp2_x, gp2_y = t[:, 3] * nG, t[:, 4] * nG\n",
        "\t\tgp3_x, gp3_y = t[:, 5] * nG, t[:, 6] * nG\n",
        "\t\tgp4_x, gp4_y = t[:, 7] * nG, t[:, 8] * nG\n",
        "\n",
        "\t\t# Get target center\n",
        "\t\tgp_x = torch.cat((gp1_x.unsqueeze(1), gp2_x.unsqueeze(1), gp3_x.unsqueeze(1), gp4_x.unsqueeze(1)), 1).view(-1, 4)\n",
        "\t\tgp_y = torch.cat((gp1_y.unsqueeze(1), gp2_y.unsqueeze(1), gp3_y.unsqueeze(1), gp4_y.unsqueeze(1)), 1).view(-1, 4)\n",
        "\n",
        "\t\tgp_x_min = torch.min(gp_x, 1)[0]\n",
        "\t\tgp_x_max = torch.max(gp_x, 1)[0]\n",
        "\t\tgp_y_min = torch.min(gp_y, 1)[0]\n",
        "\t\tgp_y_max = torch.max(gp_y, 1)[0]\n",
        "\n",
        "\t\tgp_x_center = torch.mean(torch.cat((gp_x_min.unsqueeze(1), gp_x_max.unsqueeze(1)), 1), 1)\n",
        "\t\tgp_y_center = torch.mean(torch.cat((gp_y_min.unsqueeze(1), gp_y_max.unsqueeze(1)), 1), 1)\n",
        "\t\t# Set target center in a certain cell\n",
        "\t\tgp_x_center = torch.round(gp_x_center).long()\n",
        "\t\tgp_y_center = torch.round(gp_y_center).long()\n",
        "\n",
        "\t\t# Coordinates\n",
        "\t\tt1_x[b, a, gp_y_center, gp_x_center] = gp1_x.cpu() - gp_x_center.float().cpu()\n",
        "\t\tt1_y[b, a, gp_y_center, gp_x_center] = gp1_y.cpu() - gp_y_center.float().cpu()\n",
        "\t\tt2_x[b, a, gp_y_center, gp_x_center] = gp2_x.cpu() - gp_x_center.float().cpu()\n",
        "\t\tt2_y[b, a, gp_y_center, gp_x_center] = gp2_y.cpu() - gp_y_center.float().cpu()\n",
        "\t\tt3_x[b, a, gp_y_center, gp_x_center] = gp3_x.cpu() - gp_x_center.float().cpu()\n",
        "\t\tt3_y[b, a, gp_y_center, gp_x_center] = gp3_y.cpu() - gp_y_center.float().cpu()\n",
        "\t\tt4_x[b, a, gp_y_center, gp_x_center] = gp4_x.cpu() - gp_x_center.float().cpu()\n",
        "\t\tt4_y[b, a, gp_y_center, gp_x_center] = gp4_y.cpu() - gp_y_center.float().cpu()\n",
        "\n",
        "\t\t# One-hot encoding of label\n",
        "\t\ttcls[b, a, gp_y_center, gp_x_center, tc] = 1\n",
        "\t\ttconf[b, a, gp_y_center, gp_x_center] = 1\n",
        "\n",
        "\t\tif requestPrecision:\n",
        "\t\t\t# predicted classes and confidence\n",
        "\t\t\ttb = torch.cat((gp1_x, gp1_y, gp2_x, gp2_y, gp3_x, gp3_y, gp4_x, gp4_y)).view(8, -1).t()\n",
        "\t\t\tpcls = torch.argmax(pred_cls[b, a, gp_y_center, gp_x_center], 1).cpu()\n",
        "\t\t\tpconf = torch.sigmoid(pred_conf[b, a, gp_y_center, gp_x_center].cpu()).cpu()\n",
        "\t\t\tiou_pred = bbox_iou(tb, pred_boxes[b, a, gp_y_center, gp_x_center].cpu()).cpu()\n",
        "\n",
        "\t\t\tTP[b, i] = (pconf > 0.5) & (iou_pred > 0.5) & (pcls == tc.cpu())\n",
        "\t\t\tFP[b, i] = (pconf > 0.5) & (TP[b, i] == 0)  # coordinates or class are wrong\n",
        "\t\t\tFN[b, i] = pconf <= 0.5  # confidence score is too low (set to zero)\n",
        "\n",
        "\treturn t1_x, t1_y, t2_x, t2_y, t3_x, t3_y, t4_x, t4_y, tconf, tcls, TP, FP, FN, TC\n",
        "\n",
        "def bbox_iou_nms(box1, box2):\n",
        "\tcuda = torch.cuda.is_available()\n",
        "\tdevice = torch.device('cuda:0' if cuda else 'cpu')\n",
        "\n",
        "\tnBox = box2.size()[0]\n",
        "\n",
        "\tiou = torch.zeros(nBox)\n",
        "\tpolygon1 = Polygon(box1.view(4,2)).convex_hull\n",
        "\tfor i in range(0, nBox):\n",
        "\t\tpolygon2 = Polygon(box2[i,:].view(4,2)).convex_hull\n",
        "\t\tif polygon1.intersects(polygon2):\n",
        "\t\t\ttry:\n",
        "\t\t\t\tinter_area = polygon1.intersection(polygon2).area\n",
        "\t\t\t\tunion_area = polygon1.union(polygon2).area\n",
        "\t\t\t\tiou[i] =  inter_area / union_area\n",
        "\t\t\texcept shapely.geos.TopologicalError:\n",
        "\t\t\t\tprint('shapely.geos.TopologicalError occured, iou set to 0')\n",
        "\t\t\t\tiou[i] = 0\n",
        "\n",
        "\treturn iou.to(device)\n",
        "\n",
        "\n",
        "def non_max_suppression(prediction, cls_thres=0.5, nms_thres=0.4):\n",
        "\tprediction = prediction.cpu()\n",
        "\n",
        "\toutput = [None for _ in range(len(prediction))]\n",
        "\n",
        "\tfor image_i, pred in enumerate(prediction):\n",
        "\t\tclass_prob, class_pred = torch.max(F.softmax(pred[:, 9:], 1), 1)\n",
        "\n",
        "\t\tv = (class_prob > cls_thres).numpy()\n",
        "\t\tv = v.nonzero()\n",
        "\n",
        "\t\tpred = pred[v]\n",
        "\t\tclass_prob = class_prob[v]\n",
        "\t\tclass_pred = class_pred[v]\n",
        "\n",
        "\t\t# If none are remaining => process next image\n",
        "\t\tnP = pred.shape[0]\n",
        "\t\tif not nP:\n",
        "\t\t\tcontinue\n",
        "\n",
        "\t\tdetections = torch.cat((pred[:, :9], class_prob.float().unsqueeze(1), class_pred.float().unsqueeze(1)), 1)\n",
        "\t\t# Iterate through all predicted classes\n",
        "\t\tunique_labels = detections[:, -1].cpu().unique()\n",
        "\t\tif prediction.is_cuda:\n",
        "\t\t\tunique_labels = unique_labels.cuda()\n",
        "\n",
        "\t\tfor c in unique_labels:\n",
        "\t\t\tdetections_class = detections[detections[:, -1] == c]\n",
        "\t\t\t# Sort through confidence in one class\n",
        "\t\t\t_, conf_sort_index = torch.sort(detections_class[:, 8], descending=True)\n",
        "\t\t\tdetections_class = detections_class[conf_sort_index]\n",
        "\n",
        "\t\t\tmax_detections = []\n",
        "\n",
        "\t\t\twhile detections_class.shape[0]:\n",
        "\t\t\t\t# Get detection with highest confidence and save as max detection\n",
        "\t\t\t\tmax_detections.append(detections_class[0].unsqueeze(0))\n",
        "\t\t\t\t# Stop if we're at the last detection\n",
        "\t\t\t\tif len(detections_class) == 1:\n",
        "\t\t\t\t\tbreak\n",
        "\t\t\t\t# Get the IOUs for all boxes with lower confidence\n",
        "\t\t\t\tious = bbox_iou_nms(max_detections[-1].squeeze(0)[0:8], detections_class[1:][:, 0:8])\n",
        "\n",
        "\t\t\t\t# Remove detections with IoU >= NMS threshold\n",
        "\t\t\t\tdetections_class = detections_class[1:][ious < nms_thres]\n",
        "\n",
        "\t\t\tif len(max_detections) > 0:\n",
        "\t\t\t\tmax_detections = torch.cat(max_detections).data\n",
        "\t\t\t\t# Add max detections to outputs\n",
        "\t\t\t\toutput[image_i] = max_detections if output[image_i] is None else torch.cat(\n",
        "\t\t\t\t\t(output[image_i], max_detections))\n",
        "\n",
        "\treturn output"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}